[
  {
    "objectID": "content/module1-water.html",
    "href": "content/module1-water.html",
    "title": "Module 1: Water",
    "section": "",
    "text": "Code of Conduct\n\nReview other codes\nCarpentries\nNASA TOPS - If possible this is the default, perhaps with some edits, since we are a NASA TOPS project: https://nasa.github.io/Transform-to-Open-Science-Book/About/CODE_OF_CONDUCT.html\nNASA OpenScapes.\n\n\n\nModule 1 objectives\n\nStudents will gain an understanding of the water cycle\nStudents will learn the role humans play in the water cycle.\nStudent will learn about water surpluses and deficits (anomalies)\nStudents will learn how to access GLDAS data from the NASA SEDAC website (https://www.dante-project.org/sedacr)\nStudents will learn how to access MODIS NRT flood data\nStudents will learn how to store data locally\nStudents will learn how to subset a global data set to a predefined area of interest (AOI). (GeoBoundaries?)\nStudents will learn how to summarize the data set using an area of interest\nStudents will learn how to visualize results as maps and graphs using R(?)\nStudents will learn how to estimate impacts on populations at risk (PES, POPGRID, perhaps also infrastructure with OSM)\nStudents will learn how to share their results to the cloud (using Binder?)\n\n\n\nDatasets\n\n\nCredits\nM1 Banner Photo by Jacob Kelvin.J"
  },
  {
    "objectID": "content/wsim-gldas/wsim-gldas-acquisition.html",
    "href": "content/wsim-gldas/wsim-gldas-acquisition.html",
    "title": "Acquiring and Pre-Processing the WSIM-GLDAS Dataset",
    "section": "",
    "text": "Add context for package selection\n\nstars for raster management\nsf for vector/shapefile/geojson\nlubridate for date management\n\nMore dataset context/explanation (geoBoundaries vs gadm).\nCitations and external links for data and packages.\nDecide on which wsim-gldas version to use.\n\nSwitch out the current for a 12-month integration anomaly.\n\nWrite out the smaller pre-processed file to disk for potential use in binder workshop or subsequent lesson in the module.\nIntroduce automated data acquisition with some sedac or earthdata package??"
  },
  {
    "objectID": "content/wsim-gldas/wsim-gldas-acquisition.html#to-do",
    "href": "content/wsim-gldas/wsim-gldas-acquisition.html#to-do",
    "title": "Acquiring and Pre-Processing the WSIM-GLDAS Dataset",
    "section": "",
    "text": "Add context for package selection\n\nstars for raster management\nsf for vector/shapefile/geojson\nlubridate for date management\n\nMore dataset context/explanation (geoBoundaries vs gadm).\nCitations and external links for data and packages.\nDecide on which wsim-gldas version to use.\n\nSwitch out the current for a 12-month integration anomaly.\n\nWrite out the smaller pre-processed file to disk for potential use in binder workshop or subsequent lesson in the module.\nIntroduce automated data acquisition with some sedac or earthdata package??"
  },
  {
    "objectID": "content/wsim-gldas/wsim-gldas-acquisition.html#introduction",
    "href": "content/wsim-gldas/wsim-gldas-acquisition.html#introduction",
    "title": "Acquiring and Pre-Processing the WSIM-GLDAS Dataset",
    "section": "Introduction",
    "text": "Introduction\nWSIM-GLDAS can be download from SEDAC. Downloads are organized by combination of variable (composite surplus/deficit, temperature, PETmE, runoff, soil moisture, precipitation) and integration period (1, 3, 6, 12 months). Each variable-integration combination consists of a NetCDF raster file with a time dimension that contains a raster layer for each of the 804 months between January, 1948 and December, 2014. Some variables also contain multiple attributes each with their own time dimension of 804 rasters. Hence, this is a large file that takes upwards of 2 hours to download and may cause memory issues on certain systems. We will work with the composite anomolies integrated over 1 month periods."
  },
  {
    "objectID": "content/wsim-gldas/wsim-gldas-acquisition.html#reading-the-data",
    "href": "content/wsim-gldas/wsim-gldas-acquisition.html#reading-the-data",
    "title": "Acquiring and Pre-Processing the WSIM-GLDAS Dataset",
    "section": "Reading the Data",
    "text": "Reading the Data\nOnce you’ve completed the download and placed the .nc into your working directory read in the file with the stars::read_stars() function.\n\n# proxy = TRUE will limit memory useage but does \n# not always work with certain downstream processing functions\n\nwsim_gldas_anoms &lt;- stars::read_stars(\"composite_anom_1mo.nc\", proxy = FALSE)\n\nprint(wsim_gldas_anoms)\nThe print command gives some basic information. The outputs tells us we have 5 attributes (deficit, deficit_cause, surplus, surplus_cause, both) and 3 dimensions. The first 2 dimensions are the spatial extents (x/y–longitude/latitude) and time is the 3rd dimension.\nThis means the total number of individual raster layers in this NetCDF is 4020 (5 attributes x 804 time steps/months)."
  },
  {
    "objectID": "content/wsim-gldas/wsim-gldas-acquisition.html#attribute-selection",
    "href": "content/wsim-gldas/wsim-gldas-acquisition.html#attribute-selection",
    "title": "Acquiring and Pre-Processing the WSIM-GLDAS Dataset",
    "section": "Attribute Selection",
    "text": "Attribute Selection\nWe can start paring this down by subsetting for just the combined surplus/deficit anomaly (both).\nnames(wsim_gldas_anoms)\n\nwsim_gldas_anoms &lt;- wsim_gldas_anoms['both']"
  },
  {
    "objectID": "content/wsim-gldas/wsim-gldas-acquisition.html#time-selection",
    "href": "content/wsim-gldas/wsim-gldas-acquisition.html#time-selection",
    "title": "Acquiring and Pre-Processing the WSIM-GLDAS Dataset",
    "section": "Time Selection",
    "text": "Time Selection\nSpecifying a temporal range of interest will free up more space. We’ll grab every month for 2000-2014. This can be accomplished by generating a sequence for every month between January 2000 and December 2014, and then passing that vector of dates to filter.\n# generate a vector of dates for subsetting\nkeeps&lt;-seq(lubridate::ymd(\"2000-01-01\"),\n           lubridate::ymd(\"2014-12-01\"), \n           by = \"month\")\n# filter using that vector\nwsim_gldas_anoms &lt;- dplyr::filter(wsim_gldas_anoms, time %in% keeps)\n\nprint(wsim_gldas_anoms)\nNow we’re down to a single attribute (“both”) with 180 time-steps. We can take a look at the first 6 months by passing the object through slice and then into plot.\nwsim_gldas_anoms |&gt;\n  dplyr::slice(index = 1:6, along = \"time\") |&gt;\n  plot(key.pos = 1)\nAlthough we’ve pared it down to a single attribute with a restricted time period of interest, we can take it a step further and reduce the spatial extent to a country or state of interest."
  },
  {
    "objectID": "content/wsim-gldas/wsim-gldas-acquisition.html#spatial-selection",
    "href": "content/wsim-gldas/wsim-gldas-acquisition.html#spatial-selection",
    "title": "Acquiring and Pre-Processing the WSIM-GLDAS Dataset",
    "section": "Spatial Selection",
    "text": "Spatial Selection\nWe can spatially crop the raster stack with a few different methods. Options include using a bounding box (xmin, ymin, xmax, ymax), another raster object, or a vectorized boundary like a shapefile or geojson.\nUsing a vector boundary is one of the more common geoprocessing tasks. In this example we’ll pull a geojson of the United States from the geoBoundaries API. You can also download vectorized boundaries directly from .\nThe call to geoBoundaries’ API is pretty simple:\n“https://www.geoboundaries.org/api/current/gbOpen/ISO3C/LEVEL/”\nWe adjust the bolded components of the URL address to specify the country we want using the ISO 3 Character Country Code (USA) and the desired Administrative Level (ADM1).\nusa &lt;- httr::GET(\"https://www.geoboundaries.org/api/current/gbOpen/USA/ADM1/\")\nAfter the GET call, we have to translate the content.\nusa &lt;- httr::content(usa)\n\nnames(usa)\nThe parsed content object contains 32 components. Item 29 is a direct link to the geojson file (gjDownloadURL). Read that in and check the visuals.\nusa &lt;- sf::st_read(usa$gjDownloadURL)\n\nplot(sf::st_geometry(usa))\nThis looks good, but it includes all United States territories. For simplicity, we can get it down to only the contiguous United States.\ndrops&lt;-\n  c(\"Alaska\", \"Hawaii\", \n    \"American Samoa\",\n    \"Puerto Rico\",\n    \"Commonwealth of the Northern Mariana Islands\", \n    \"Guam\", \n    \"United States Virgin Islands\")\n\nusa&lt;-usa[!(usa$shapeName %in% drops),]\n\nplot(sf::st_geometry(usa))\nWe can take this a step further and select a target state.\ntexas &lt;- usa[usa$shapeName == \"Texas\",]\n\nplot(sf::st_geometry(texas))\nFrom here we can crop the WSIM GLDAS raster stack by indexing it with the stored boundary of Texas\nwsim_gldas_anoms_tex &lt;- wsim_gldas_anoms[texas]\nFor a final visual check we’ll take the last time-step in the WSIM-GLDAS dataset (180/December, 2014) and plot it with an overlay of the Texas boundary.\nwsim_gldas_anoms_tex |&gt;\n  dplyr::slice(index = 180, along = \"time\") |&gt;\n  plot(reset = FALSE)\n\nplot(sf::st_geometry(texas),\n     add = TRUE,\n     lwd = 3,\n     fill = NA,\n     border = 'purple')\nThe subsetted dataset may be written to disk, and saved for future modules.\nstars::write_stars(wsim_gldas_anoms_tex, \"wsim_gldas_tex.nc\")\nThe size of the pre-processed dataset is 1.6 MB compared to the original dataset of 1.7 GB. This is much more manageable in cloud environments, workshops, and git platforms."
  },
  {
    "objectID": "content/Hotspot_Training.html",
    "href": "content/Hotspot_Training.html",
    "title": "En Español. ANALYSIS DE PUNTOS CRITICOS DE VULNERABILIDAD - I-GUIDE Workshop 2023 New York",
    "section": "",
    "text": "Entrenamiento provedido en Español  Training offered in English"
  },
  {
    "objectID": "content/Hotspot_Training.html#indexing-and-weighting-method",
    "href": "content/Hotspot_Training.html#indexing-and-weighting-method",
    "title": "En Español. ANALYSIS DE PUNTOS CRITICOS DE VULNERABILIDAD - I-GUIDE Workshop 2023 New York",
    "section": "Indexing and Weighting Method",
    "text": "Indexing and Weighting Method\nThe Hotspot Vulnerability Analysis method is borrowed from the CIESIN Step-by-Step Guide to Vulnerability Hotspots Mapping: Implementing the Spatial Index Approach. This method develops a data-driven model that allows for varied nominal variables –whether they are absolute, physical, unitless, or indexes– to be transformed to the same range and be comparatively measured. Each component that is introduced is first transformed from a range from 0 to 100, where 0 represents the lowest and 100 represents the highest levels of vulnerability. All of the components introduced are weighted based on the level of importance placed by the user. The weights of the components can be changed to adjust the model. The weighted components are added together and indexed again into a single Hotspot Vulnerability Index (HVI)."
  },
  {
    "objectID": "content/Hotspot_Training.html#estudio-de-caso-de-municipios-del-cauca-colombia",
    "href": "content/Hotspot_Training.html#estudio-de-caso-de-municipios-del-cauca-colombia",
    "title": "En Español. ANALYSIS DE PUNTOS CRITICOS DE VULNERABILIDAD - I-GUIDE Workshop 2023 New York",
    "section": "Estudio de Caso de Municipios del Cauca, Colombia",
    "text": "Estudio de Caso de Municipios del Cauca, Colombia\nEn esta lección, desarrollaremos un índice de vulnerabilidad de puntos críticos (HVI) para cada uno de los municipios del Cauca, Colombia, para medir tres componentes ambientales y uno socioeconómico para determinar qué municipios son los más vulnerables. Identificamos cuatro componentes del bienestar que queremos medir: pobreza multidimensional, calor, agua y aire. - Pobreza Multidimensional: Medida por el Índice de Pobreza Multidimensional (IPM) del DANE. - Calor: medido por la temperatura máxima diurna de la superficie terrestre en Celsius (LST). - Agua: Medida por la evolución de la disponibilidad de agua terrestre (Agua). - Calidad del aire: medida por partículas finas a nivel del suelo de 2,5 micrómetros o menos en microgramos por metro cúbico (PM2,5). \n\n Fuentes de datos:\nLímites Municipales de Colombia (Shapefile)Índice de Pobreza Multidimensional del Valle del Cauca (Table) Valle del Cauca Cuadrículas globales de temperatura de la superficie terrestre (LST) de verano, v1 (2013) (Raster) Tendencias en la disponibilidad global de agua dulce del Experimento climático y de recuperación de la gravedad (GRACE), v1 (2002 – 2016) (Raster)Valle del Cauca Global (GL) Anual PM2.5 Cuadrículas de MODIS, MISR y SeaWiFS Aerosol Profundidad óptica (AOD), v4.03 (2019) (Raster)"
  },
  {
    "objectID": "content/Hotspot_Training.html#case-study-of-municipalities-in-cauca-colombia",
    "href": "content/Hotspot_Training.html#case-study-of-municipalities-in-cauca-colombia",
    "title": "En Español. ANALYSIS DE PUNTOS CRITICOS DE VULNERABILIDAD - I-GUIDE Workshop 2023 New York",
    "section": "Case Study of Municipalities in Cauca, Colombia",
    "text": "Case Study of Municipalities in Cauca, Colombia\nIn this lesson, we will develop a hotspot vulnerability index (HVI) for each of the municipalities in Cauca, Colombia to measure four components, three environmental and one socioeconomic, to determine which municipalities are the most vulnerable. We identified four components of wellbeing that we want to measure: multidimensional poverty, heat, water, and air. - Multidimensonal Poverty: Measured by the DANE Multidimensional Poverty Index (IPM). - Heat: Measured by Land Surface Temperature daytime maximum in Celcius (LST). - Water: Measured by trends in terrestrial water availability (Water). - Air Quality: Measured by ground-level fine particulate matter of 2.5 micrometers or smaller in micrograms per cubic meter (PM2.5).\n\nData Sources:\nColombia Municipal Boundaries (Shapefile)\nValle del Cauca Multidimensional Poverty Index (Table)\nValle del Cauca Global Summer Land Surface Temperature (LST) Grids, v1 (2013) (Raster)\nTrends in Global Freshwater Availability from the Gravity Recovery and Climate Experiment (GRACE), v1 (2002 – 2016) (Raster)\nValle del Cauca Global (GL) Annual PM2.5 Grids from MODIS, MISR and SeaWiFS Aerosol Optical Depth (AOD), v4.03 (2019) (Raster)\n\nImportar archivos –shapefile, tabla, y tres geoTiffs.\nZonas utilizadas para delimitar zonas. Los valores de zona deben ser números enteros: #### Import files –shapefile, table, and three geoTiffs. Zones used to delineate zones. Zone Values should be integers:\n\n\nCode\n#assing shapefile to zones\nzones = gpd.read_file(\"/vsicurl/https://github.com/ciesin-geospatial/hotspot_training/raw/e9e2492f7c682422fe72c4328afe4dc36ba4871f/data/Col_CAUCA_municip.shp\")\n#vista previa de las primeras cinco filas\n#preview first five rows\nzones.head()\n\n\n\n\nCode\n#Importar tabla índice de pobreza multidimensional (IPM)\n#Import multidimensional poverty index table (IPM)\nIPM = pd.read_csv(\"https://github.com/ciesin-geospatial/hotspot_training/raw/e9e2492f7c682422fe72c4328afe4dc36ba4871f/data/cauca_IPM.csv\", index_col=False, decimal=\",\")\nIPM.head()\n\n\n\n\nCode\n#lista de columnas\n#column list\nIPM.columns\n\n\n\n\nCode\n#Ver los variables unicos en la columna 'clase'\n#View the unique variables in column 'clase' (class)\nIPM[\"clase\"].unique()\n\n\n\n\nCode\n#tabla de subconjuntos para incluir solo filas con 'Total' en la columna 'clase'\n#subset table to include only rows with 'Total' in the 'class' column\nIPM  = IPM[IPM[\"clase\"] == \"Total\"]\nIPM.head()\n\n\n\n\nCode\n#seleccione solo las columnas de código municipal, nombre e IPM\n#select only the columns for municipal code, name and IPM\nIPM = IPM[[\"cod_municipio\", \"municipio\", \"ipm\"]]\n\n#cambiar el nombre de la columna del código municipal a 'MID'\n#rename municipal code column to 'MID'\nIPM = IPM.rename(columns={\"cod_municipio\": \"MID\"})\nIPM.head()\n\n\n\n\nCode\n#archivos de datos utilizados para realizar estadísticas zonales\n#files of data used to perform zonal statistics\n\n#Temperatura de la superficie terrestre (LST)\n#Land Surface Temperature (LST)\nLST = rasterio.open(\"https://github.com/ciesin-geospatial/hotspot_training/raw/e9e2492f7c682422fe72c4328afe4dc36ba4871f/data/summer_LST.tif\")\n#disponibilidad de agua dulce (agua)\n#freshwater availability (water)\nwater = rasterio.open(\"https://github.com/ciesin-geospatial/hotspot_training/raw/e9e2492f7c682422fe72c4328afe4dc36ba4871f/data/freshwater.tif\")\n#partículas de ozono 2.5 (PM25)\n#ozone particulate matter 2.5 (PM25)\nPM25 = rasterio.open(\"https://github.com/ciesin-geospatial/hotspot_training/raw/e9e2492f7c682422fe72c4328afe4dc36ba4871f/data/PM25.tif\")\n\n#leer banda 1 del ráster LST\n#read LST raster band 1\nLST_data = LST.read(1, masked=True)\n\n#leer banda 1 del ráster water\n#read water raster band 1\nwater_data = water.read(1, masked=True)\n\n#leer banda 1 del ráster PM25\n#read PM25 raster band 1\nPM25_data = PM25.read(1, masked=True)\n\n\n\n\n\nCode\n#crea una gráfica con 1 fila y 4 columnas limitando el tamaño a 20 por 5\n#create a plot with 1 row and 4 columns limiting size to 20 by 5\nfig, ax = plt.subplots(1,4, figsize = (20,5))\n\n\n#traza el archivo de forma de zonas en la primera columna llamada ax[0]\n#plot the zones shapefile in the first column named ax[0]\nzones.plot(cmap = 'rainbow', ax=ax[0])\n\n#trazar rásteres en el resto de las columnas\n#plot rasters in the rest of the columns\nim1 = ax[1].imshow(LST_data, cmap='plasma')\nim2 = ax[2].imshow(water_data, cmap='GnBu')\nim3 = ax[3].imshow(PM25_data, cmap='viridis')\n\n#establecer títulos para gráficos\n#set titles for graphs\nax[0].set_title('Cauca - Municipalidades', wrap=True)\nax[1].set_title('Cauca - Temperatura de la\\nsuperficie terrestre de verano', wrap=True);\nax[2].set_title('Cauca - Disponibilidad de\\nagua dulce', wrap=True);\nax[3].set_title('Cauca - Material particulado 2.5\\n(PM2.5)', wrap=True);\n\n#barra de colores para rásteres\n#color bar for rasters\nfig.colorbar(im1, ax=ax[1])\nfig.colorbar(im2, ax=ax[2])\nfig.colorbar(im3, ax=ax[3])\n\nplt.show()\n\n\n\nEjemplo de una municipalidad:\n\n\nExample of one Municipality:\n\n\nCode\n#recorra IDs de zona (MID)\n#loop through zone IDs (MID)\nfor i in zones['MID'][:1]:\n    #Printear MID\n    #Print MID\n    print(\"MID:\", i)\n\n    #obtener forma única de shapefile\n    #get single shape from shapefile\n    roi = zones[zones.MID == i]\n\n\n    #enmáscarar los rásteres y establezca nodata en -9999\n    #mask rasters and set nodata to -9999\n    LST_arr, LSTbound = mask.mask(LST, roi[\"geometry\"], crop=True, all_touched=True, nodata=-9999)\n    water_arr, waterbound = mask.mask(water, roi[\"geometry\"], crop=True, all_touched=True, nodata=-9999)\n    PM25_arr, PM25bound = mask.mask(PM25, roi[\"geometry\"], crop=True, all_touched=True, nodata=-9999)\n\n    #establezca nodata (-9999) a None\n    #Set nodata value (-9999) to None\n    LST_arr[LST_arr ==-9999] = None\n    water_arr[water_arr ==-9999] = None\n    PM25_arr[PM25_arr ==-9999] = None\n\n#trazar el gráfico\n#plot the arrays\nshow(LST_arr)\nshow(water_arr)\nshow(PM25_arr)\n\n\n\n\n\nRecorra todos los municipios:\n\n\nLoop through all municipalities:\n\n\nCode\n#Crear marco de datos en blanco para almacenar estadísticas zonales\n#Create blank dataframe to store zonal statistics\ndf = pd.DataFrame(columns =['MID','LST','water','PM25'])\n\n#recorra IDs de zona (MID)\n#loop through zone IDs (MID)\nfor i in zones['MID']:\n\n    #obtener fila de municipio único de shapefile\n    #get single municipality row from shapefile\n    roi = zones[zones.MID == i]\n\n    #enmáscarar los rásteres y establezca nodata en -9999\n    #Mask rasters with single municipality geometry and set nodata to -9999\n    LST_arr, LSTbound = mask.mask(LST, roi[\"geometry\"], crop=True, all_touched=True, nodata=-9999)\n    water_arr, waterbound = mask.mask(water, roi[\"geometry\"], crop=True, all_touched=True, nodata=-9999)\n    PM25_arr, PM25bound = mask.mask(PM25, roi[\"geometry\"], crop=True, all_touched=True, nodata=-9999)\n\n    #establezca nodata (-9999) a None\n    #Set nodata value (-9999) to None\n    LST_arr[LST_arr ==-9999] = None\n    water_arr[water_arr ==-9999] = None\n    PM25_arr[PM25_arr ==-9999] = None\n\n    #crear fila para agregar datos de fila al marco de datos\n    #create row to append row data to dataframe\n    row_to_append = pd.DataFrame([{'MID':i, 'LST': np.nanmean(LST_arr),\n                                   'water':np.nanmean(water_arr),\n                                   'PM25': np.nanmean(PM25_arr)}])\n    #agregar datos de fila al marco de datos\n    #append row data and dataframe\n    df = pd.concat([df,row_to_append])\ndf.head()\n\n\n\n\n\nCode\n#combinar table IPM con table df\n#comine IPM and df tables\ndf = pd.merge(IPM,df, on=\"MID\", how=\"left\")\ndf.head()\n\n\n\n\nCode\n#histogramas\n#histograms\ndf.hist()\n\n\n\n\nCode\n#prueba transformaciones\n#test out transformations\ntest = np.power(df['water'], 1.25)\n\n\n# test = boxcox(df['PM25'], lmbda=None)[0]\n# test = pd.DataFrame(list(test))\ntest.hist()\n\n\n\n\nCode\n#transformar columnas\n#transform columns\ndf[\"water\"]= np.power(df['water'], 1.25)\ndf[\"PM25\"]= boxcox(df['PM25'], lmbda=None)[0]\ndf.hist()"
  },
  {
    "objectID": "NRT_flood-Test.html",
    "href": "NRT_flood-Test.html",
    "title": "NRT_flood_test",
    "section": "",
    "text": "Libraries:\nlibrary(stars)\ndownload_link &lt;- \"https://nrt3.modaps.eosdis.nasa.gov/api/v2/content/archives/MCDWD_L3_F3_NRT.A2023324.h09v06.061.tif\"\nx &lt;- read_stars(download_link)\nplot(x, axes = TRUE)"
  },
  {
    "objectID": "NRT_flood-Test.html#nrt-flood-test",
    "href": "NRT_flood-Test.html#nrt-flood-test",
    "title": "NRT_flood_test",
    "section": "",
    "text": "Libraries:\nlibrary(stars)\ndownload_link &lt;- \"https://nrt3.modaps.eosdis.nasa.gov/api/v2/content/archives/MCDWD_L3_F3_NRT.A2023324.h09v06.061.tif\"\nx &lt;- read_stars(download_link)\nplot(x, axes = TRUE)"
  },
  {
    "objectID": "modules.html",
    "href": "modules.html",
    "title": "SCHOOL MODULES",
    "section": "",
    "text": "Module 1: Water\nThe Water module is the first of a series of seven TOPST Science Modules. This module is provided in a Jupyter Notebook format. Module 1: Water\n\n\nModule 2: Air Quality\nComing soon…"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "\nTOPSTSCHOOL\n",
    "section": "",
    "text": "TOPSTSCHOOL\n\n\n\nScience Core Heuristics for Open Science Outcomes in Learning (SCHOOL), part of the NASA Transform to Open Science (TOPS) Training (TOPST) initiative SITE UNDER CONSTRUCTION\n\n\n\nThe TOPST Science Core Heuristics for Open Science Outcomes in Learning project is developing seven modules that will be part of NASA’s Transform to Open Science curriculum. Each 2.5-hour module will teach students how to apply Open Science principles to scientific research in a specific thematic area. We are asking for your participation in this workshop to help the Development Team formulate use cases for the module on water resources with the principles of inclusive teaching and active learning in mind.\nProject announcements: TOPSTSCHOOL •\nLearn about our recent work: Blog Posts • Presentations • SEDAC • CIESIN • iSciences • Baruch College\nPlease connect with us at TOPSTSCHOOL@gmail.com"
  },
  {
    "objectID": "cookbook-navbar-page.html",
    "href": "cookbook-navbar-page.html",
    "title": "NASA Earthdata Cloud Cookbook",
    "section": "",
    "text": "The NASA Earthdata-Openscapes Mentors team and other contributors are creating open educational resources to help researchers migrate workflows to the Cloud - all available for learning, reuse, and remix.\nExplore these resources in the NASA Earthdata Cloud Cookbook."
  },
  {
    "objectID": "dev-team.html",
    "href": "dev-team.html",
    "title": "SCHOOL Development Team",
    "section": "",
    "text": "SCHOOL TOPS Team Members\n\nModule 1: Water\nMarie Curie\nNobel Prize pioneering research on radioactivity as head of the Physics Laboratory at the Sorbonne-Université\nCarl Sagan\nAmaron\n\n\nModule 2\n\n\nModule 3\n\n\n\nSCHOOL Subject Matter Experts (SMEs)\n\nPedagogy\nTom M. Parris\niSciences President\n\n\nModule 1: Water\nTom M. Parris\nPresident at iSciences Laureline M. Josset\nAssociate Research Scientist at Columbia Water Center\n\n\nModule 2\n\n\nModule 3\n\n\n\nSCHOOL Development Team\nDeborah Balk \nDirector at the CUNY Institute for Demographic Research and professor at Baruch College\nJosh Brinks \nResearch Scientist at iSciences\nChristina Alexia Deodatis \nResearch Staff Assistant at CIESIN, Columbia Climate School\nHasim Engin \nGeographic Information Specialist at CIESIN, Columbia Climate School\nCamilla Green\nResearch Staff Assistant at CIESIN, Columbia Climate School\nKytt MacManus\nAssistant Systems Engineer at NASA Socioeconomic Data and Applications Center \\((\\)SEDAC\\()\\) and GIS Developer at CIESIN, Columbia Climate School\nJuan Fernando Martinez\nSenior Research Staff Assistant at CIESIN, Columbia Climate School\nJosie Morkin \nResearch Staff Assistant at CIESIN, Columbia Climate School\nTom M. Parris\nPresident at iSciences\nLinda Pistolesi \nSenior Geographic Information Specialist at CIESIN, Columbia Climate School\nSri Vinay \nDeputy Manager & System Engineer at NASA Socioeconomic Data and Applications Center \\((\\)SEDAC\\()\\) and Associate Director for IT at CIESIN, Columbia Climate School\nGreg Yetman \nAssociate Director for Geospatial Applications at CIESIN, Columbia Climate School\n\n&lt;!DOCTYPE html&gt;\n\n\n\n\n\n\n\n\n&lt;a target=\"_self\" href=\"TOPSTSCHOOL-logo03.png\"&gt;\n  &lt;img src=\"./images/TOPSTSCHOOL-logo03.png\" width=\"600\" height=\"400\"&gt;\n&lt;/a&gt;\n&lt;div class=\"desc\"&gt;TOPSLOGO&lt;/div&gt;\n\n\n\n\n&lt;a target=\"_blank\" href=\"img_forest.jpg\"&gt;\n  &lt;img src=\"img_forest.jpg\" width=\"600\" height=\"400\"&gt;\n&lt;/a&gt;\n&lt;div class=\"desc\"&gt;Add a description of the image here&lt;/div&gt;\n\n\n\n\n&lt;a target=\"_blank\" href=\"img_lights.jpg\"&gt;\n  &lt;img src=\"img_lights.jpg\" width=\"600\" height=\"400\"&gt;\n&lt;/a&gt;\n&lt;div class=\"desc\"&gt;Add a description of the image here&lt;/div&gt;\n\n\n\n\n&lt;a target=\"_blank\" href=\"img_mountains.jpg\"&gt;\n  &lt;img src=\"img_mountains.jpg\" width=\"600\" height=\"400\"&gt;\n&lt;/a&gt;\n&lt;div class=\"desc\"&gt;Add a description of the image here&lt;/div&gt;"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "SCHOOL’s objective is to develop curriculum for ScienceCore that incorporates NASA Earth Science Applications use cases and data into the data science life cycle as part of NASA’s Open Source Science Initiative (OSSI). The project consists of seven 2.5 hour learning modules designed to fit both online (self-led) and in person instruction. Modules focus on demonstrating the data science life cycle with varying themes: Water, Health and Air Quality, Environmental Justice, Disasters, Wildfires, Agriculture, and Climate.\n\n\n\nInclusive Teaching\n\n\nInclusive teaching fosters an environment where diversity is celebrated and reflected in course content.\n\n\nMarginalization of various populations is overcome by using multiple and diverse examples crossing gender, cultural, and socioeconomic barriers. Course content is designed to provide a variety of modes (visual, textual, interactive) for content delivery and for student expression which is absent of assumptions about student abilities or experiences.\n\n\nActive Learning\n\n\nThe process of encouraging students to not only focus on doing, but also to think critically about what they are doing.\n\n\nActive learning engages students through activities such as reading, discussing, executing code, and writing, in addition to listening.\n\n\nIn asynchronous learning environments, active learning strategies move beyond listening to prerecorded materials and toward active engagement by directing students to do something, such as looking at an image, interacting with the real world, or retrieving past knowledge.\n\n\nEvaluations\n\n\nTo foster inclusive teaching and active learning, it is critical that\n\n\n\nexpectations for assessment are clearly communicated\n\n\nthat assessments are timely\n\n\nthat examples of ideal results are presented\n\n\n\n\nClearly defined learning objectives allow instructors to assess metrics of student performance, and to provide feedback early and often."
  },
  {
    "objectID": "about.html#school",
    "href": "about.html#school",
    "title": "About",
    "section": "",
    "text": "SCHOOL’s objective is to develop curriculum for ScienceCore that incorporates NASA Earth Science Applications use cases and data into the data science life cycle as part of NASA’s Open Source Science Initiative (OSSI). The project consists of seven 2.5 hour learning modules designed to fit both online (self-led) and in person instruction. Modules focus on demonstrating the data science life cycle with varying themes: Water, Health and Air Quality, Environmental Justice, Disasters, Wildfires, Agriculture, and Climate.\n\n\n\nInclusive Teaching\n\n\nInclusive teaching fosters an environment where diversity is celebrated and reflected in course content.\n\n\nMarginalization of various populations is overcome by using multiple and diverse examples crossing gender, cultural, and socioeconomic barriers. Course content is designed to provide a variety of modes (visual, textual, interactive) for content delivery and for student expression which is absent of assumptions about student abilities or experiences.\n\n\nActive Learning\n\n\nThe process of encouraging students to not only focus on doing, but also to think critically about what they are doing.\n\n\nActive learning engages students through activities such as reading, discussing, executing code, and writing, in addition to listening.\n\n\nIn asynchronous learning environments, active learning strategies move beyond listening to prerecorded materials and toward active engagement by directing students to do something, such as looking at an image, interacting with the real world, or retrieving past knowledge.\n\n\nEvaluations\n\n\nTo foster inclusive teaching and active learning, it is critical that\n\n\n\nexpectations for assessment are clearly communicated\n\n\nthat assessments are timely\n\n\nthat examples of ideal results are presented\n\n\n\n\nClearly defined learning objectives allow instructors to assess metrics of student performance, and to provide feedback early and often."
  },
  {
    "objectID": "about.html#topstschool-module-structure",
    "href": "about.html#topstschool-module-structure",
    "title": "About",
    "section": "TOPSTSCHOOL Module Structure",
    "text": "TOPSTSCHOOL Module Structure\nEach 2.5 hour thematic module, broken down into five 30-minute lessons, will demonstrate the full data science life cycle and connect those processes with open science principles.\n\n\n\n\nModule Component\n\n\nData Science Life Cycle/Open Science Integration\n\n\nExample Activity\n\n\n\n\nLesson 1\n\n\nGeneration and collection\n\n\nIdentify and obtain data sources. Generation could include spatializing tabular data.\n\n\n\n\nLesson 2\n\n\nProcessing and sotarge\n\n\nData integration tasks are completed. Local and cloud storage options are demonstrated.\n\n\n\n\nLesson 3\n\n\nManagement and analysis\n\n\nCreation of metadata to inform uses and structure. Statistical techniques applied.\n\n\n\n\nLesson 4\n\n\nVisualization and interpretation\n\n\nCreation of charts and maps. Interpretation thought questions and examples from other work.\n\n\n\n\nLesson 5\n\n\nOpen Science and Community Engagement\n\n\nHow to share these results openly. Practice of engaging with existing and emerging community networks."
  },
  {
    "objectID": "about.html#project-timeline",
    "href": "about.html#project-timeline",
    "title": "About",
    "section": "Project Timeline",
    "text": "Project Timeline\nThe project will commence on July 1, 2023 and end on June 30, 2025. Learning modules will be developed using the SAFe methodology which will allow for the regular incremental release of thematic content as it becomes available."
  },
  {
    "objectID": "about.html#learn-more",
    "href": "about.html#learn-more",
    "title": "About",
    "section": "Learn More",
    "text": "Learn More"
  },
  {
    "objectID": "get-involved.html",
    "href": "get-involved.html",
    "title": "Join the NASA TOPSTSCHOOL Team",
    "section": "",
    "text": "We are looking for researchers to join as Subject Matter Experts (SMEs) on our SCHOOL project advisory committee for one module. Your expertise is vital in developing learning modules applying Open Science principles to the module topics. Researchers will engage in workshops and short sprints in a hybrid, open-meeting format.\nThe SCHOOL Project aims to empower students to apply Open Science principles to thematic areas, including Water, Health and Air Quality, Environmental Justice, Disasters, Wildfires, Agriculture, and Climate. We’re particularly interested in team members passionate about inclusive pedagogy. To join as a Subject Matter Expert or learn more, please fill out the SME Google Form or contact us at TOPSTSCHOOL@ciesin.columbia.edu."
  },
  {
    "objectID": "get-involved.html#subject-matter-experts",
    "href": "get-involved.html#subject-matter-experts",
    "title": "Join the NASA TOPSTSCHOOL Team",
    "section": "",
    "text": "We are looking for researchers to join as Subject Matter Experts (SMEs) on our SCHOOL project advisory committee for one module. Your expertise is vital in developing learning modules applying Open Science principles to the module topics. Researchers will engage in workshops and short sprints in a hybrid, open-meeting format.\nThe SCHOOL Project aims to empower students to apply Open Science principles to thematic areas, including Water, Health and Air Quality, Environmental Justice, Disasters, Wildfires, Agriculture, and Climate. We’re particularly interested in team members passionate about inclusive pedagogy. To join as a Subject Matter Expert or learn more, please fill out the SME Google Form or contact us at TOPSTSCHOOL@ciesin.columbia.edu."
  },
  {
    "objectID": "get-involved.html#open-science-team",
    "href": "get-involved.html#open-science-team",
    "title": "Join the NASA TOPSTSCHOOL Team",
    "section": "Open Science Team",
    "text": "Open Science Team\nWe are looking for participants to join the Open Science Team to give input on the development of learning modules. Participants will engage in workshops and short sprints in a hybrid, open-meeting format. Our workshop focuses on FAIR and CARE principles in learning, making us particularly interested in team members with a passion for inclusive pedagogy. Following the launch workshop, participants will be asked for feedback during two 1-hour remote participation meetings. To join the Open Science Team or learn more, please fill out the Participant Google Form or contact us at TOPSTSCHOOL@ciesin.columbia.edu."
  },
  {
    "objectID": "get-involved.html#fall-2023-mentors-give-workshops-at-agu",
    "href": "get-involved.html#fall-2023-mentors-give-workshops-at-agu",
    "title": "Join the NASA TOPSTSCHOOL Team",
    "section": "Fall 2023: Mentors give workshops at AGU",
    "text": "Fall 2023: Mentors give workshops at AGU\nDecember 11 - 15, NASA Openscapes Mentors will attend the AGU annual meeting and deliver workshops. High-level planning happens in the 2023-planning-agu GitHub repo."
  },
  {
    "objectID": "get-involved.html#summer-2023-mentors-retreat-at-esip",
    "href": "get-involved.html#summer-2023-mentors-retreat-at-esip",
    "title": "Join the NASA TOPSTSCHOOL Team",
    "section": "Summer 2023: Mentors Retreat at ESIP",
    "text": "Summer 2023: Mentors Retreat at ESIP\nThe July 17 NASA Openscapes Mentors Retreat will bring together mentors from across seven+ DAACs that have engaged as leaders in the NASA Openscapes project. We see the main value of this retreat as a chance to solidify these cross-DAAC relationships, share lessons learned, problem solve, and ignite new collaborations across the DAACs.\nOver the last two years, the mentors have built a community across DAACs, created resources in the Earthdata Cloud Cookbook and supported early adopter users migrating their workflows to the cloud. The goal of the 1-day retreat is to plan the long-term sustainability of the Mentors community from both the governance and technical side.\nThe NASA Openscapes Mentor Retreat will be in Burlington, Vermont on Monday, July 17 before the ESIP Summer Meeting, July 18-21. We will also provide the opportunity for the Mentors to attend the ESIP Meeting in order to network and learn from the broader community. All registration, travel, accommodation, per diems will be covered."
  },
  {
    "objectID": "get-involved.html#spring-2023",
    "href": "get-involved.html#spring-2023",
    "title": "Join the NASA TOPSTSCHOOL Team",
    "section": "Spring 2023",
    "text": "Spring 2023\n\nApril-June 2023: Openscapes Champions Cohort\nSee https://nasa-openscapes.github.io/champions for more details!"
  },
  {
    "objectID": "get-involved.html#winter-2023",
    "href": "get-involved.html#winter-2023",
    "title": "Join the NASA TOPSTSCHOOL Team",
    "section": "Winter 2023",
    "text": "Winter 2023\n\nMarch 2023: ESDSWG\nDetails soon\n\n\nMarch 2023: Women in Data Science Conference\nhttps://www.widsconference.org/\nWe will share how we developed the Openscapes Flywheel to support the NASA DAAC Mentors, and some of their acheivements and momentum!\n\n\nFebruary 2023: EMIT Workshop\nhttps://github.com/nasa/EMIT-Data-Resources\nThis workshop was designed to be completed locally, however it was offered to use the Openscapes 2i2c JupyterHub cloud workspace to revisit the EMIT Data Tutorials Workshops hosted February 3, 10, and 17th 2023. The Feb 17th event had 91 active users in large python instances in the 2i2c JupyterHub; Aaron Friesz, Bri Lind (LP DAAC) and Luis Lopez (NSIDC) worked ahead of time with 2i2c engineers to accommodate the increased CPU needs for this workshop.\n\n\nJanuary 2023: ESIP\nNASA Openscapes is involved with 3 talks on Tuesday and Wednesday. We’re looking forward to seeing you at these and other ESIP sessions:\n\nAmy Steiker speaking in Enabling Open Science with NASA’s Earthdata in the Cloud\nJulie Lowndes speaking in Earth and Space Science Knowledge Commons: From vision to implementation\nBrianna Pagan speaking in Bringing Cloud-Native Science “Down To Earth”\nLuis Lopez and Cassie Nickles speaking in Better science for future us: Openscapes stories and approaches for the Year of Open Science"
  },
  {
    "objectID": "get-involved.html#fall-2022",
    "href": "get-involved.html#fall-2022",
    "title": "Join the NASA TOPSTSCHOOL Team",
    "section": "Fall 2022",
    "text": "Fall 2022\n\nAmerican Geophysical Union (AGU) Fall Conference\n3 posters, hackathon, and plenary lightning talk!"
  },
  {
    "objectID": "get-involved.html#summer-2022",
    "href": "get-involved.html#summer-2022",
    "title": "Join the NASA TOPSTSCHOOL Team",
    "section": "Summer 2022",
    "text": "Summer 2022\nKeynote at RStudio Conference - “Hello Quarto: share • collaborate • teach • reimagine”. We shared how we support NASA Earthdata DAACs as part of the global launch of Quarto, an open source publishing framework that we contributed to as first external users and has been a big part of “place” - having a place to collaborate across the DAACs. Blog post with link to slides and video: https://openscapes.org/blog/2022/08/10/quarto-keynote"
  },
  {
    "objectID": "get-involved.html#spring-2022",
    "href": "get-involved.html#spring-2022",
    "title": "Join the NASA TOPSTSCHOOL Team",
    "section": "Spring 2022",
    "text": "Spring 2022\n\nApril 2022 ECOSTRESS Workshop\nPoint of contact: Aaron Friesz\nhttps://nasa-openscapes.github.io/2022-ECOSTRESS-Cloud-Workshop/\n\n\nMarch 2022 GES DISC Internal Cloud Workshop\nPoint of contact: Alexis Hunzinger\n\n\nMarch 2022. PO.DAAC SWOT Oceanography Workshop\nPoint of contact: Catalina Oaida\nhttps://podaac.github.io/2022-SWOT-Ocean-Cloud-Workshop/\n\n\nMarch 2022. Earthdata Cloud Services Working Group\nPoint of contact: Amy Steiker\nhttps://nasa-openscapes.github.io/earthdata-cloud-cookbook/examples/Transform-workflow.html\n\n\nMarch-April 2022. Openscapes Champions Cohort\nNASA Openscapes Champions is a mentorship and professional development opportunity for research teams using data from NASA Distributed Active Archive Centers (DAACs) and interested in open science and migrating their analytical workflows to the cloud. Learn more and nominate your team: https://nasa-openscapes.github.io/champions."
  },
  {
    "objectID": "get-involved.html#section",
    "href": "get-involved.html#section",
    "title": "Join the NASA TOPSTSCHOOL Team",
    "section": "2021",
    "text": "2021\nJanuary 21, 2021. ESIP\nWe are leading a session at ESIP’s Winter Meeting: Better Science for Future Us: Planning for the Year of Open Science.\nBlog summary:\n\nhttps://www.openscapes.org/blog/2022/02/17/esip-winter-2022\n\nDecember 12 2021. AGU Fall Meeting Workshop (Virtual)\nNASA’s Earth Science Data Systems (ESDS) Program promotes open data access for open science. The workshop will highlight novel applications that utilize EOSDIS data in the cloud. Participants will leave having a better understanding of how NASA Earthdata Cloud data and services can best be leveraged and integrated within their work across a variety of disciplines and data types. Details: https://agu.confex.com/agu/fm21/meetingapp.cgi/Session/124026; https://nasa-openscapes.github.io/2021-Cloud-Workshop-AGU/ \nNovember 15-19 2021. Cross-DAAC Cloud Hackathon\nThe NASA-Openscapes Framework is part of a collaborative Cross-DAAC hackathon to help transition workflows to the cloud. All details and tutorials are available at: https://nasa-openscapes.github.io/2021-Cloud-Hackathon/\nBlog summaries:\n\nhttps://earthdata.nasa.gov/learn/articles/2021-cloud-hackathon\nhttps://podaac.jpl.nasa.gov/announcements/2021-12-15-The-2021-Cloud-Hackathon\n\nAugust-September 2021. DAAC User Working Group Presentations\nThe NASA-Openscapes Framework is being shared at DAAC User Working Group meetings including:\n\nLP DAAC, August 12, 2021 (Slides)\nGES DISC, September 8, 2021\nNSIDC DAAC, September 16, 2021\n\nJune 30, 2021. NASA Openscapes Framework presented at Pangeo Showcase\nOur project was presented at the Pangeo Showcase, a weekly webinar that highlights relevant work around the Python/Earth science community. The talk and slides can be found on their website. \nJune 21-24, 2021. Carpentries Instructor Training\nThis is the suggested session for Carpentries Instructor training for the Mentor Cohort. Mentors can also attend later events. \nMay 17-18, 2021. Carpentries Workshop: Intro to Linux/Shell, Python, Git\nThis workshop is open to NASA Earth science data users, hosted by Openscapes, NASA, and the NASA Atmospheric Science Data Center (ASDC) DAAC.\nFor more information and to register: https://virdi.github.io/2021-05-17-openscapes-online/ \nMarch 2021 - Feb 2021. Openscapes Champions Mentors: DAAC Cohort\nWe are supporting and strengthening the community of DAAC folks that are already creating cloud learning resources. Through Openscapes mentorship, Carpentries instructor training, and 2i2c cloud services, these DAAC mentors will work together to create learning resources for their teams and communities. \nFeb 2021. Openscapes and Collaborators Announce Openscapes NASA Project\nWe are thrilled to announce that NASA awarded Openscapes and partners a 3-year project to utilize the Openscapes Framework and support researchers using NASA Earthdata as it moves to the cloud. Openscapes and it’s host institution, NCEAS, Metadata Game Changers and NASA’s Earthdata Blog all shared posts about the award."
  },
  {
    "objectID": "content/SCHOOL_module1_water.html",
    "href": "content/SCHOOL_module1_water.html",
    "title": "Module 1: Water",
    "section": "",
    "text": "Module 1: Water is part of the Science Core Heuristics for Open Science Outcomes in Learning (SCHOOL),a part of the NASA Transform to Open Science (TOPS) Training (TOPST) initiative."
  },
  {
    "objectID": "content/SCHOOL_module1_water.html#subtitle",
    "href": "content/SCHOOL_module1_water.html#subtitle",
    "title": "Module 1: Water",
    "section": "Subtitle",
    "text": "Subtitle\nregular text bold text ### Sub Sub title regular text"
  },
  {
    "objectID": "content/SCHOOL_module1_water.html#datasets-1",
    "href": "content/SCHOOL_module1_water.html#datasets-1",
    "title": "Module 1: Water",
    "section": "Datasets",
    "text": "Datasets"
  },
  {
    "objectID": "content/SCHOOL_module1_water.html#photos",
    "href": "content/SCHOOL_module1_water.html#photos",
    "title": "Module 1: Water",
    "section": "Photos",
    "text": "Photos\nModule 1 Banner Photo by Jacob Kelvin.J"
  },
  {
    "objectID": "content/wsim-gldas/wsim-gldas-vis.html",
    "href": "content/wsim-gldas/wsim-gldas-vis.html",
    "title": "WSIM-GLDAS Dataset Exploration and Visualizations",
    "section": "",
    "text": "Write the actual code and narrative.\nDetermine the region and time period of focus to draw in our use cases/human focused stories.\nDetermine the method of exploration.\n\nMimic our process?\n\n12 month integration panels of the CON USA from 2000-2014 to identify areas of interest.\nZoom in to locations of interest and switch to 1-month integration for the years identified in the previous step."
  },
  {
    "objectID": "content/wsim-gldas/wsim-gldas-vis.html#to-do",
    "href": "content/wsim-gldas/wsim-gldas-vis.html#to-do",
    "title": "WSIM-GLDAS Dataset Exploration and Visualizations",
    "section": "",
    "text": "Write the actual code and narrative.\nDetermine the region and time period of focus to draw in our use cases/human focused stories.\nDetermine the method of exploration.\n\nMimic our process?\n\n12 month integration panels of the CON USA from 2000-2014 to identify areas of interest.\nZoom in to locations of interest and switch to 1-month integration for the years identified in the previous step."
  },
  {
    "objectID": "content/wsim-gldas/wsim-gldas-vis.html#introduction",
    "href": "content/wsim-gldas/wsim-gldas-vis.html#introduction",
    "title": "WSIM-GLDAS Dataset Exploration and Visualizations",
    "section": "Introduction",
    "text": "Introduction\n\nRaster/vector visualization background?\n\nGeneral\nWater resource specific\n\nPackage background\n\nBasic plotting with stars/sf\nmore advanced plotting with ggplot/ggmap"
  },
  {
    "objectID": "content/wsim-gldas/wsim-gldas-vis.html#setup",
    "href": "content/wsim-gldas/wsim-gldas-vis.html#setup",
    "title": "WSIM-GLDAS Dataset Exploration and Visualizations",
    "section": "Setup",
    "text": "Setup\nlibrary(stars) # raster manipulation\nlibrary(sf) # vector manipulation\nlibrary(ggplot2) # advanced plotting\nlibrary(lubridate) # date/time manipulation\nlibrary(exactextractr) # zonal statistics"
  },
  {
    "objectID": "content/wsim-gldas/wsim-gldas-vis.html#load-data",
    "href": "content/wsim-gldas/wsim-gldas-vis.html#load-data",
    "title": "WSIM-GLDAS Dataset Exploration and Visualizations",
    "section": "Load Data",
    "text": "Load Data\nLoad in data from previous vignette.\nI think the previous vignette should end with a 2000-2014 12-month integration CONUS dataset.\n\nVerify data structure with print or summary."
  },
  {
    "objectID": "content/wsim-gldas/wsim-gldas-vis.html#exploratory-histogram",
    "href": "content/wsim-gldas/wsim-gldas-vis.html#exploratory-histogram",
    "title": "WSIM-GLDAS Dataset Exploration and Visualizations",
    "section": "Exploratory Histogram",
    "text": "Exploratory Histogram\nCreate histogram of raster values for a single time step.\nBasic plotting method is OK, but check if it can be done with ggplotso we can use a uniform palette across all modules.\n\nExtreme values or other items of note might require additional visualization or other data exploration."
  },
  {
    "objectID": "content/wsim-gldas/wsim-gldas-vis.html#multi-panel-time-series",
    "href": "content/wsim-gldas/wsim-gldas-vis.html#multi-panel-time-series",
    "title": "WSIM-GLDAS Dataset Exploration and Visualizations",
    "section": "Multi-Panel Time Series",
    "text": "Multi-Panel Time Series\nCreate a multipanel time series of 12 month integration CONUSA; similar to what we used to identify our case studies. Each panel will represent 1 year.\nLoad in a CONUSA geojson from geoBoundaries. Copy methods from previous vignette.\n\nStart with the basic plotting commands–create the time series with slice or other method used in previous vignette.\n\nThe palette will not exist and be difficult to use.\nTry a built in palette for stars (not sure if possible?).\nIntroduce the official WSIM palette. This may only be helpful within a ggplot function.\n# numbers are return period values for a composite surplus (blues) and deficit (reds) dataset\nleg_colors&lt;-c(\n    '#9B0039',\n    # -50 to -40\n    '#D44135',\n    # -40 to -20\n    '#FF8D43',\n    # -20 to -10\n    '#FFC754',\n    # -10 to -5\n    '#FFEDA3',\n    # -5 to -3\n    '#FFFFFF',\n    # -3 to 3\n    '#CEFFAD',\n    # 3 to 5\n    '#00F3B5',\n    # 5 to 10\n    '#00CFCE',\n    # 10 to 20\n    '#009ADE',\n    # 20 to 40\n    '#0045B5')\nOnce hot spots are easily identified pick a region of interest to zoom in on using the 1 month integration dataset.\nLoad in the 1 month integration dataset and subset/index the dataset to the region of interest (copy code from previous vignette). Use dplyr::slice or other method to pull out just the 12 months from the year of interest. Code demonstrating these techniques in previous vignette.\n\nCreate a multi-panel figure with each panel representing 1 month to identify the most intense months of drought or flooding. Starting with this one maybe use ggplot and a nice palette, legend, and panel headings. Will probably have to use some sort of faceting to make individual panels (might not be possible)."
  },
  {
    "objectID": "content/wsim-gldas/wsim-gldas-vis.html#use-case-background",
    "href": "content/wsim-gldas/wsim-gldas-vis.html#use-case-background",
    "title": "WSIM-GLDAS Dataset Exploration and Visualizations",
    "section": "Use Case Background",
    "text": "Use Case Background\nNow that we’ve keyed in on a particular event, bring in the backup information we’ve collected to discuss what actually happened."
  },
  {
    "objectID": "content/wsim-gldas/wsim-gldas-vis.html#point-location-time-series",
    "href": "content/wsim-gldas/wsim-gldas-vis.html#point-location-time-series",
    "title": "WSIM-GLDAS Dataset Exploration and Visualizations",
    "section": "Point Location Time Series",
    "text": "Point Location Time Series\nVisualize an individual cell with particular extreme or maybe volatile values. Use Google Maps to identify the latitude/longitude of a place of interest. Maybe an urban center or other important location in the region that suffered from the extreme event.\nCreate a vector with the point location.\n\nUse stars::extract to extract raster values in the stack at the point location.\n\nThe resulting data frame of time series values should be inspected. It may also need to be converted from wide format to long format so it may be plotted in ggplot. Use either pivot wider/longer from dplyr or cast/melt from data.table.\n\nOnce in the proper format, plot using ggplot."
  },
  {
    "objectID": "content/wsim-gldas/wsim-gldas-vis.html#population-exposure-plot",
    "href": "content/wsim-gldas/wsim-gldas-vis.html#population-exposure-plot",
    "title": "WSIM-GLDAS Dataset Exploration and Visualizations",
    "section": "Population Exposure Plot",
    "text": "Population Exposure Plot\nUse Gridded Population of the World and exactextractr to determine the number of people exposed to a given anomaly for each month of the year.\nBackground info on GPW would be appropriate. Same with exactextractr and zonal statistics.\nLoad in GPW data and the exactextractr package\n\nPerform the time series zonal summary.\nThis might be a bit tricky; been a while for me. Have to look up the proper code. Dan has good examples on the exactextractr package website.\nResulting data.frame will probably need to be transformed to long (just like before), so it can be plotted.\n\nNow plot the data in ggplot. I have some existing code I can pull to help with the plotting–or at least make it fancy."
  }
]